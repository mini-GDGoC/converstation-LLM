from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
import cv2
import numpy as np
import easyocr
from PIL import Image
import io
import time
# from paddleocr import PaddleOCR

import matplotlib.pyplot as plt
from dotenv import load_dotenv
from modules.llm_model import init_model, get_model
from modules.database import get_db, get_menu_info
from modules.models import MenuItem
from modules.get_button_llm import get_button, reset_button_memory
from modules.divide_question_llm import divide_question, reset_divide_memory
from modules.test_one_llm import handle_screen_input, handle_user_input

import os

from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
from langchain.chains import ConversationChain
from langchain.memory import ConversationBufferMemory
from fastapi.responses import JSONResponse
from langchain_core.messages import BaseMessage
from langchain.prompts import PromptTemplate

from modules.dto import ChatRequest, ButtonRequest, QuestionRequest

# .env ë¶ˆëŸ¬ì˜¤ê¸°
load_dotenv()

# FastAPI ì¸ìŠ¤í„´ìŠ¤
app = FastAPI()

# ocr reader
reader = easyocr.Reader(['ko', 'en'])


# LLM ì„¤ì • (OpenAI)
llm = ChatOpenAI(
    model="gpt-4o",  # ë˜ëŠ” "gpt-4", "gpt-4o", "gpt-4.1", "gpt-4.1-mini", "gpt-4.1-nano"
    temperature=0.7,
    api_key=os.getenv("OPENAI_API_KEY")  # ì—¬ê¸°ì— .env í‚¤ ë“¤ì–´ê°
)



# ìƒˆ ConversationChain ìƒì„±
memory = ConversationBufferMemory(return_messages=True)

@app.on_event("startup")
async def startup():
    init_model()
    print("Model init")
    # print(get_model().invoke("í•˜ì´")) #ì‹¤ì œ ëª¨ë¸ ë™ìž‘ í•˜ëŠ”ì§€ í…ŒìŠ¤íŠ¸ (ì£¼ì„ ì²˜ë¦¬ í•´ë†“ì§€ ì•Šìœ¼ë©´ ë¦¬ë¡œë“œ í•  ë•Œë§ˆë‹¤ ê³„ì† í˜¸ì¶œ í•´ì„œ api ì‚¬ìš©ëŸ‰ ê¹Œë¨¹ìŒ)

    db = get_db()
    print("DB init")
    global conversation
    menu_info = get_menu_info()
    custom_prompt = PromptTemplate.from_template(f""" 
                                             ë„ˆëŠ” ë””ì§€í„¸ ê¸°ê¸°ê°€ ìµìˆ™í•˜ì§€ ì•Šì€ ì–´ë¥´ì‹ ë“¤ì„ ë„ì™€ì£¼ëŠ” ë”°ëœ»í•œ AI ë„ìš°ë¯¸ì•¼.
- í•­ìƒ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•˜ê³ , ë§íˆ¬ëŠ” ë¶€ë“œëŸ½ê³  ì¹œì ˆí•´ì•¼ í•´. ì†ìžì²˜ëŸ¼ ì¹œê·¼í•œ ë§íˆ¬ë¡œ í•´ì¤˜.
- ì–´ë ¤ìš´ ê¸°ìˆ  ìš©ì–´ë‚˜ ì˜ì–´ í‘œí˜„ì€ ì“°ì§€ ë§ê³ , ì‰¬ìš´ ë‹¨ì–´ë¡œ ë°”ê¿”ì„œ ì„¤ëª…í•´ì¤˜.
- ì–´ë¥´ì‹ ì´ ë©”ë‰´ì— ì—†ëŠ” í•­ëª©ì„ ë§í•˜ì…”ë„, â€œì—†ìŠµë‹ˆë‹¤â€ë¼ê³  ë‹¨ì •í•˜ì§€ ë§ê³  **ë¹„ìŠ·í•œ ë©”ë‰´ë‚˜ ìƒìœ„ ë¶„ë¥˜ ê¸°ì¤€ìœ¼ë¡œ ìžì—°ìŠ¤ëŸ½ê²Œ ìœ ë„í•´ì¤˜.**
- ì£¼ë¬¸ì´ ë‹¤ ëë‚œ ê²ƒ ê°™ìœ¼ë©´ "ê²°ì œë¥¼ ì§„í–‰í•©ë‹ˆë‹¤"ë¼ê³  ë§í•´ì¤˜.
---

### ðŸ” íŠ¸ë¦¬ ê¸°ë°˜ ì¶”ì²œ ë°©ì‹

- **ì‚¬ìš©ìžê°€ ìƒìœ„ ë©”ë‰´(ì˜ˆ: í–„ë²„ê±°)** ë¥¼ ì–¸ê¸‰í•˜ë©´:
  - `í–„ë²„ê±°` ë©”ë‰´ì˜ í•˜ìœ„ ë¶„ë¥˜ì¸ **ì†Œê³ ê¸° / ë‹­ê³ ê¸° / ìƒˆìš°** ì¤‘ ì–´ë–¤ ìž¬ë£Œê°€ ì¢‹ìœ¼ì‹ ì§€ ì§ˆë¬¸í•´ì¤˜.
  - ì˜ˆ: â€œí–„ë²„ê±°ê°€ ë“œì‹œê³  ì‹¶ìœ¼ì‹œêµ°ìš”! ì†Œê³ ê¸°, ë‹­ê³ ê¸°, ìƒˆìš° ì¤‘ì— ì–´ë–¤ ê³ ê¸°ë¥¼ ë„£ì€ í–„ë²„ê±°ê°€ ì¢‹ìœ¼ì„¸ìš”?â€

- **ì‚¬ìš©ìžê°€ ì¤‘ê°„ ë¶„ë¥˜(ì˜ˆ: ì†Œê³ ê¸°)** ë¥¼ ì„ íƒí•˜ë©´:
  - ê·¸ í•˜ìœ„ ë©”ë‰´ë“¤(ì˜ˆ: ê³ ê¸° ë‘ ìž¥, ë‹¬ë‹¬í•œ ì†ŒìŠ¤, ì¹˜ì¦ˆ ë§Žì´ ë“±)ì„ ê¸°ì¤€ìœ¼ë¡œ ì§ˆë¬¸ì„ ìœ ë„í•´ì¤˜.
  - ì˜ˆ: â€œì†Œê³ ê¸°ê°€ ë“¤ì–´ê°„ í–„ë²„ê±°ëŠ” ë”ë¸”íŒ¨í‹°ë²„ê±°, ë¶ˆê³ ê¸°ë²„ê±°, ë”ë¸”ì¹˜ì¦ˆë²„ê±° ê°™ì€ ë©”ë‰´ê°€ ìžˆì–´ìš”. ì–´ë–¤ ìŠ¤íƒ€ì¼ì´ ë” ëŒë¦¬ì„¸ìš”?â€

- AIëŠ” í•­ìƒ íŠ¸ë¦¬ êµ¬ì¡°ë¥¼ ê¸°ì–µí•˜ê³ , ì„ íƒì§€ê°€ ìžˆë‹¤ë©´ í•˜ìœ„ ë©”ë‰´ë¥¼ ë³´ì—¬ì£¼ê³  ì§ˆë¬¸ìœ¼ë¡œ ìœ ë„í•´ì¤˜.

---

### ðŸ§  ì§€ê¸ˆê¹Œì§€ì˜ ë©”ë‰´ ë¶„ë¥˜ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ì•„:
{menu_info}

---
                                             - ì´ëª¨í‹°ì½˜ì€ ì‚¬ìš©í•˜ì§€ ë§ì•„ì¤˜.
                                        
                                             ëŒ€í™” ê¸°ë¡:
                                             {{history}}
                                             ì‚¬ìš©ìž: {{input}}
                                             AI:
                                             """)  
    conversation = ConversationChain(
        llm=llm,
        memory=memory,
        prompt=custom_prompt,
        verbose=True
    )

    # for i in db.query(MenuItem).all():
    #     print(i.id, i.parent_id, i.name, i.description, i.emoji, i.keywords)



@app.post("/chat")
async def chat(req: ChatRequest):
    start_time = time.time()
    response = conversation.predict(input=req.message)
    total_time = round(time.time() - start_time, 4)

    return JSONResponse(content={"response": response, "process_time": total_time})

@app.get("/chat-history")
async def chat_history():
    history = [
        {"role": m.type, "content": m.content}
        for m in memory.chat_memory.messages
    ]
    return JSONResponse(content={"history": history})


# ê²°ì œ ì™„ë£Œ ë˜ë©´ memory ì´ˆê¸°í™”
@app.post("/reset-chat")
async def reset_chat():
    memory.clear()
    return {"message": "ëŒ€í™” ë‚´ìš©ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."}

@app.get("/")
def read_root():
    return {"message": f"Update"}

# # easyocr
@app.post("/ocr-test")
async def ocr_test(file: UploadFile = File(...)):
    start_time = time.time()
    # image load
    image_bytes = await file.read()
    image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    image_np = np.array(image)

    # opencvìš© bgrë¡œ ë³€í™˜
    image_bgr = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)

    gray = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2GRAY)

    # 3. CLAHE ê°ì²´ ìƒì„± (clipLimit ë†’ì¼ìˆ˜ë¡ ëŒ€ë¹„ ê°•í•´ì§)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    contrast_enhanced = clahe.apply(gray)

    # ë°ì€ ì˜ì—­ë§Œ ë§ˆìŠ¤í‚¹ (threshold ì ìš©)
    _, bright_mask = cv2.threshold(contrast_enhanced, 100, 255, cv2.THRESH_BINARY)
    bright_only = cv2.bitwise_and(image_bgr, image_bgr, mask=bright_mask)
    bright_rgb = cv2.cvtColor(bright_only, cv2.COLOR_BGR2RGB)

    # detect text and position
    results = reader.readtext(bright_rgb)

    buttons = []
    for (bbox, text, prob) in results:
        if prob > 0.5:  # ì‹ ë¢°ë„ ê¸°ì¤€
            (tl, tr, br, bl) = bbox
            x_min = int(min(tl[0], bl[0]))
            y_min = int(min(tl[1], tr[1]))
            x_max = int(max(tr[0], br[0]))
            y_max = int(max(bl[1], br[1]))
            buttons.append({
                "text": text,
                "bbox": {
                    "x": x_min,
                    "y": y_min,
                    "width": x_max - x_min,
                    "height": y_max - y_min
                }
            })

    visible_button_texts = [b['text'] for b in buttons]
    conversation.prompt.partial_variables = {"visible_buttons": ', '.join(visible_button_texts)}

    # LLMì—ê²Œ ì§ˆë¬¸ ì¶”ì²œ ìš”ì²­
    question_prompt = f"ì§€ê¸ˆ í™”ë©´ì— ë³´ì´ëŠ” ë©”ë‰´ í•­ëª©ì€ ë‹¤ìŒê³¼ ê°™ì•„: {', '.join(visible_button_texts)}. ì´ê±¸ ë³´ê³  ì–´ë¥´ì‹ ì—ê²Œ ì–´ë–¤ ì§ˆë¬¸ì„ í•˜ë©´ ì¢‹ì„ê¹Œ? í•œë¬¸ìž¥ ì •ë„ì˜ ì§ˆë¬¸ìœ¼ë¡œ í•´ì¤˜."
    suggested_question = conversation.predict(input=question_prompt)

    total_time = round(time.time() - start_time, 4)
    return JSONResponse(content={
        "buttons": buttons,
        "suggested_question": suggested_question,
        "process_time": total_time
    })

# # OCR
# # PaddleOCR ì´ˆê¸°í™” - ì—¬ëŸ¬ ì–¸ì–´ ì§€ì›
# ocr = None
# try:
#     ocr = PaddleOCR(use_angle_cls=True, lang='korean')
#     print("âœ… PaddleOCR korean_english ëª¨ë¸ ì´ˆê¸°í™” ì„±ê³µ")
# except Exception as e:
#     print(f"âŒ PaddleOCR ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
#     raise RuntimeError("OCR ì´ˆê¸°í™” ì‹¤íŒ¨")


# @app.post("/get-position")
# async def get_position(file: UploadFile = File(...)):
    # global ocr

    # image_bytes = await file.read()
    # image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
    # image_np = np.array(image)

    # ocr_result = ocr.ocr(image_np)

    # buttons = []

    # if isinstance(ocr_result, list) and len(ocr_result) > 0 and isinstance(ocr_result[0], dict):
    #     result_dict = ocr_result[0]

    #     polys = result_dict.get("dt_polys", []) or result_dict.get("rec_boxes", [])
    #     texts = result_dict.get("rec_texts", [])
    #     scores = result_dict.get("rec_scores", [])

    #     for i, (box, text, score) in enumerate(zip(polys, texts, scores)):
    #         if score > 0.5:
    #             try:
    #                 if hasattr(box, 'tolist'):
    #                     box = box.tolist()
    #                 x_coords = [int(p[0]) for p in box]
    #                 y_coords = [int(p[1]) for p in box]
    #                 x_min, x_max = min(x_coords), max(x_coords)
    #                 y_min, y_max = min(y_coords), max(y_coords)

    #                 buttons.append({
    #                     "text": text,
    #                     "confidence": float(score),
    #                     "bbox": {
    #                         "x": x_min,
    #                         "y": y_min,
    #                         "width": x_max - x_min,
    #                         "height": y_max - y_min
    #                     }
    #                 })
    #             except Exception as e:
    #                 print(f"[ì˜¤ë¥˜] box ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    #                 continue

    # return JSONResponse(content={
    #     "buttons": buttons,
    #     "count": len(buttons)
    # })

@app.post("/get_button/chat") 
async def get_button_llm(req: ButtonRequest):
    # return await get_button(req)
    return await handle_user_input(req)

@app.post("/get-button/reset")
async def reset_button_llm():
    return await reset_button_memory()

@app.post("/divide_question/chat") 
async def divide_question_llm(req: QuestionRequest):
    # return await divide_question(req)
    return await handle_screen_input(req)


@app.post("/divide_question/reset") 
async def reset_divide_llm():
    return await reset_divide_memory()

@app.post("/test-one-llm")
async def test_one_llm():
    print(get_menu_info())
    return JSONResponse(content={
        "db": "succes",
    })